{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj_24vd8tb77"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # Clone YOLOv5 repository\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTzazLcYtcga",
        "outputId": "ee128d81-7c94-43f8-a2bf-306e78776a33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To determine the evaluation metrics for the detections which are observed by YOLOv5 and Faster R-CNN"
      ],
      "metadata": {
        "id": "R-fnMFZErzwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the path to the folder containing the images\n",
        "folder_path = '/content/drive/MyDrive/Smart-Beach-Predict-People/test-data'\n",
        "\n",
        "# Create the \"output\" folder if it doesn't exist\n",
        "output_folder = '/content/drive/MyDrive/Smart-Beach-Predict-People/test-data/op'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv5 model\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
        "yolo_model.eval()\n",
        "\n",
        "# Load Faster R-CNN model\n",
        "frcnn_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "frcnn_model.eval()\n",
        "\n",
        "# Confidence threshold for YOLOv5\n",
        "yolo_confidence_threshold = 0.7\n",
        "\n",
        "# Confidence threshold for Faster R-CNN\n",
        "frcnn_confidence_threshold = 0.7\n",
        "\n",
        "# Function to divide the image into 4 zones using one horizontal and one vertical line\n",
        "def divide_into_zones(image):\n",
        "    width, height = image.size\n",
        "    # Define coordinates for the vertical and horizontal lines\n",
        "    vertical_line = width // 2\n",
        "    horizontal_line = height // 2\n",
        "\n",
        "    # Define the zones\n",
        "    zones = [\n",
        "        (0, 0, vertical_line, horizontal_line),                   # Zone 1\n",
        "        (vertical_line, 0, width, horizontal_line),              # Zone 2\n",
        "        (0, horizontal_line, vertical_line, height),             # Zone 3\n",
        "        (vertical_line, horizontal_line, width, height)          # Zone 4\n",
        "    ]\n",
        "\n",
        "    return zones\n",
        "\n",
        "# Function to perform object detection using YOLOv5\n",
        "def detect_objects_yolo(image):\n",
        "    results = yolo_model(image)\n",
        "    bboxes = results.xyxy[0][:, :4].cpu().numpy()  # Bounding boxes\n",
        "    class_indices = results.xyxy[0][:, 5].cpu().numpy().astype(int)  # Class indices\n",
        "    class_names = [results.names[idx] for idx in class_indices]  # Class names\n",
        "    return bboxes, class_names\n",
        "\n",
        "\n",
        "# Function to perform object detection using Faster R-CNN\n",
        "def detect_objects_frcnn(image):\n",
        "    image_tensor = T.ToTensor()(image)\n",
        "    with torch.no_grad():\n",
        "        prediction = frcnn_model([image_tensor])[0]\n",
        "    bboxes = prediction['boxes'].cpu().numpy()\n",
        "    labels = prediction['labels'].cpu().numpy()\n",
        "    scores = prediction['scores'].cpu().numpy()\n",
        "    class_names = [str(i) for i in labels]  # Dummy class names as we're not using actual class names here\n",
        "    return bboxes, class_names\n",
        "\n",
        "# Function to perform ensemble voting\n",
        "def ensemble_voting(images):\n",
        "    bboxes_yolo = []\n",
        "    class_names_yolo = []\n",
        "    bboxes_frcnn = []\n",
        "    labels_frcnn = []\n",
        "\n",
        "    for image in images:\n",
        "        bboxes_y, class_names_y = detect_objects_yolo(image)\n",
        "        bboxes_yolo.append(bboxes_y)\n",
        "        class_names_yolo.append(class_names_y)\n",
        "\n",
        "        bboxes_f, class_names_f = detect_objects_frcnn(image)\n",
        "        bboxes_frcnn.append(bboxes_f)\n",
        "        labels_frcnn.append(class_names_f)\n",
        "\n",
        "    return bboxes_yolo, class_names_yolo, bboxes_frcnn, labels_frcnn\n",
        "\n",
        "# Function to compute IoU between two bounding boxes\n",
        "def compute_iou(box1, box2):\n",
        "    # Compute intersection coordinates\n",
        "    x1_intersection = max(box1[0], box2[0])\n",
        "    y1_intersection = max(box1[1], box2[1])\n",
        "    x2_intersection = min(box1[2], box2[2])\n",
        "    y2_intersection = min(box1[3], box2[3])\n",
        "\n",
        "    # Compute intersection area\n",
        "    intersection_area = max(0, x2_intersection - x1_intersection + 1) * max(0, y2_intersection - y1_intersection + 1)\n",
        "\n",
        "    # Compute union area\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    # Compute IoU\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# Function to evaluate precision, recall, and accuracy\n",
        "def evaluate_performance(gt_bboxes, pred_bboxes, iou_threshold=0.5):\n",
        "    num_gt = len(gt_bboxes)\n",
        "    num_pred = len(pred_bboxes)\n",
        "\n",
        "    # Initialize lists to store matched ground truth and predicted indices\n",
        "    matched_gt_indices = []\n",
        "    matched_pred_indices = []\n",
        "\n",
        "    # Match predicted bounding boxes to ground truth boxes based on IoU\n",
        "    for i in range(num_gt):\n",
        "        for j in range(num_pred):\n",
        "            iou = compute_iou(gt_bboxes[i], pred_bboxes[j])\n",
        "            # If the IoU is above the threshold and the ground truth box is not already matched\n",
        "            if iou >= iou_threshold and i not in matched_gt_indices and j not in matched_pred_indices:\n",
        "                matched_gt_indices.append(i)\n",
        "                matched_pred_indices.append(j)\n",
        "\n",
        "    # Calculate precision, recall, and accuracy\n",
        "    precision = len(matched_gt_indices) / num_pred if num_pred > 0 else 0\n",
        "    recall = len(matched_gt_indices) / num_gt if num_gt > 0 else 0\n",
        "    accuracy = len(matched_gt_indices) / num_gt if num_gt > 0 else 0\n",
        "\n",
        "    return precision, recall, accuracy\n",
        "\n",
        "# Function to classify objects and count their occurrences within each zone\n",
        "def classify_and_count_objects(image, zones):\n",
        "    # Perform ensemble voting\n",
        "    bboxes_yolo, _, bboxes_frcnn, _ = ensemble_voting([image])\n",
        "\n",
        "    # Convert bounding boxes to list of tuples\n",
        "    bboxes_yolo = [(bbox[0], bbox[1], bbox[2], bbox[3]) for bbox in bboxes_yolo[0]]\n",
        "    bboxes_frcnn = [(bbox[0], bbox[1], bbox[2], bbox[3]) for bbox in bboxes_frcnn[0]]\n",
        "\n",
        "    # Evaluate performance\n",
        "    precision, recall, accuracy = evaluate_performance(bboxes_yolo, bboxes_frcnn)\n",
        "\n",
        "    # Process YOLOv5 results\n",
        "    zone_counts = {zone_id: {} for zone_id in range(len(zones))}\n",
        "    for bbox in bboxes_yolo:\n",
        "        for zone_id, zone_coords in enumerate(zones):\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            if zone_coords[0] <= x1 <= zone_coords[2] and zone_coords[1] <= y1 <= zone_coords[3]:\n",
        "                if 'Object' in zone_counts[zone_id]:\n",
        "                    zone_counts[zone_id]['Object'] += 1\n",
        "                else:\n",
        "                    zone_counts[zone_id]['Object'] = 1\n",
        "                break\n",
        "\n",
        "    return zone_counts, precision, recall, accuracy\n",
        "\n",
        "# Iterate over each image file\n",
        "for image_file in os.listdir(folder_path):\n",
        "    # Construct the full path to the image file\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "    # Skip directories\n",
        "    if os.path.isdir(image_path):\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Load the original image\n",
        "        original_image = Image.open(image_path)\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"Error: Unable to identify image file '{image_path}'. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Divide the image into 4 zones\n",
        "    zones = divide_into_zones(original_image)\n",
        "\n",
        "    # Classify objects, count their occurrences within each zone, and evaluate performance\n",
        "    zone_counts, precision, recall, accuracy = classify_and_count_objects(original_image, zones)\n",
        "\n",
        "    # Create a figure and axis for plotting\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Plot the original image with the 4 zones\n",
        "    axs[0].imshow(original_image)\n",
        "    for zone_id, zone_coords in enumerate(zones):\n",
        "        rect = plt.Rectangle((zone_coords[0], zone_coords[1]),\n",
        "                             zone_coords[2] - zone_coords[0],\n",
        "                             zone_coords[3] - zone_coords[1],\n",
        "                             fill=False, edgecolor='red', linewidth=2)\n",
        "        axs[0].add_patch(rect)\n",
        "        axs[0].text(zone_coords[0] + 5, zone_coords[1] + 20, f'Zone {zone_id + 1}',\n",
        "                    color='red', fontsize=12, weight='bold')\n",
        "\n",
        "    # Plot the count information beside the image\n",
        "    axs[1].axis('off')\n",
        "    for zone_id, zone_counts_dict in zone_counts.items():\n",
        "        zone_str = f'Zone {zone_id + 1} Counts:\\n'\n",
        "        count_str = '\\n'.join([f'- {class_name}: {count}' for class_name, count in zone_counts_dict.items()])\n",
        "        axs[1].text(0.5, 0.95 - 0.25 * zone_id, zone_str + count_str,\n",
        "                    transform=axs[1].transAxes, fontsize=12, weight='bold')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the modified image with both the original image and counts\n",
        "    output_path = os.path.join(output_folder, f\"output_{image_file}\")\n",
        "    plt.savefig(output_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Processed image with counts saved at: {output_path}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "lghGOV1Ztcjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To detect the object counts using the image classification of Yolov5 and Faster R-CNN models"
      ],
      "metadata": {
        "id": "SXH9Y9-Csgdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Define the path to the folder containing the images\n",
        "folder_path = '/content/drive/MyDrive/Smart-Beach-Predict-People/test-data'\n",
        "\n",
        "# Create the \"output\" folder if it doesn't exist\n",
        "output_folder = '/content/drive/MyDrive/Smart-Beach-Predict-People/test-data/op'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv5 model\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
        "yolo_model.eval()\n",
        "\n",
        "# Load Faster R-CNN model\n",
        "frcnn_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "frcnn_model.eval()\n",
        "\n",
        "# Confidence threshold for YOLOv5\n",
        "yolo_confidence_threshold = 0.2\n",
        "\n",
        "# Confidence threshold for Faster R-CNN\n",
        "frcnn_confidence_threshold = 0.5\n",
        "\n",
        "# Function to divide the image into 4 zones using one horizontal and one vertical line\n",
        "def divide_into_zones(image):\n",
        "    width, height = image.size\n",
        "    # Define coordinates for the vertical and horizontal lines\n",
        "    vertical_line = width // 2\n",
        "    horizontal_line = height // 2\n",
        "\n",
        "    # Define the zones\n",
        "    zones = [\n",
        "        (0, 0, vertical_line, horizontal_line),                   # Zone 1\n",
        "        (vertical_line, 0, width, horizontal_line),              # Zone 2\n",
        "        (0, horizontal_line, vertical_line, height),             # Zone 3\n",
        "        (vertical_line, horizontal_line, width, height)          # Zone 4\n",
        "    ]\n",
        "\n",
        "    return zones\n",
        "\n",
        "# Function to perform object detection using YOLOv5\n",
        "def detect_objects_yolo(image):\n",
        "    results = yolo_model(image)\n",
        "    bboxes = results.xyxy[0][:, :4].cpu().numpy()  # Bounding boxes\n",
        "    class_indices = results.xyxy[0][:, 5].cpu().numpy().astype(int)  # Class indices\n",
        "    class_names = [results.names[idx] for idx in class_indices]  # Class names\n",
        "    return bboxes, class_names\n",
        "\n",
        "\n",
        "# Function to perform object detection using Faster R-CNN\n",
        "def detect_objects_frcnn(image):\n",
        "    image_tensor = T.ToTensor()(image)\n",
        "    with torch.no_grad():\n",
        "        prediction = frcnn_model([image_tensor])[0]\n",
        "    bboxes = prediction['boxes'].cpu().numpy()\n",
        "    labels = prediction['labels'].cpu().numpy()\n",
        "    scores = prediction['scores'].cpu().numpy()\n",
        "    class_names = [str(i) for i in labels]  # Dummy class names as we're not using actual class names here\n",
        "    return bboxes, class_names\n",
        "\n",
        "# Function to perform ensemble voting\n",
        "def ensemble_voting(images):\n",
        "    bboxes_yolo = []\n",
        "    class_names_yolo = []\n",
        "    bboxes_frcnn = []\n",
        "    labels_frcnn = []\n",
        "\n",
        "    for image in images:\n",
        "        bboxes_y, class_names_y = detect_objects_yolo(image)\n",
        "        bboxes_yolo.append(bboxes_y)\n",
        "        class_names_yolo.append(class_names_y)\n",
        "\n",
        "        bboxes_f, class_names_f = detect_objects_frcnn(image)\n",
        "        bboxes_frcnn.append(bboxes_f)\n",
        "        labels_frcnn.append(class_names_f)\n",
        "\n",
        "    return bboxes_yolo, class_names_yolo, bboxes_frcnn, labels_frcnn\n",
        "\n",
        "# Function to classify objects and count their occurrences within each zone\n",
        "def classify_and_count_objects(image, zones):\n",
        "    # Perform ensemble voting\n",
        "    bboxes_yolo, class_names_yolo, bboxes_frcnn, labels_frcnn = ensemble_voting([image])\n",
        "\n",
        "    # Process YOLOv5 results\n",
        "    zone_counts = {zone_id: {} for zone_id in range(len(zones))}\n",
        "    for bbox, class_name in zip(bboxes_yolo[0], class_names_yolo[0]):\n",
        "        for zone_id, zone_coords in enumerate(zones):\n",
        "            x1, y1, x2, y2 = bbox.astype(int)\n",
        "            if zone_coords[0] <= x1 <= zone_coords[2] and zone_coords[1] <= y1 <= zone_coords[3]:\n",
        "                if class_name in zone_counts[zone_id]:\n",
        "                    zone_counts[zone_id][class_name] += 1\n",
        "                else:\n",
        "                    zone_counts[zone_id][class_name] = 1\n",
        "                break\n",
        "\n",
        "    return zone_counts\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "def calculate_metrics(true_labels, pred_labels):\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
        "    return precision, recall, fscore\n",
        "\n",
        "# Create lists to store true and predicted labels\n",
        "true_labels_list = []\n",
        "pred_labels_list = []\n",
        "\n",
        "# Iterate over each image file\n",
        "for image_file in os.listdir(folder_path):\n",
        "    # Construct the full path to the image file\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "    # Skip directories\n",
        "    if os.path.isdir(image_path):\n",
        "        continue\n",
        "\n",
        "    # Load the original image\n",
        "    original_image = Image.open(image_path)\n",
        "\n",
        "    # Divide the image into 4 zones\n",
        "    zones = divide_into_zones(original_image)\n",
        "\n",
        "    # Classify objects, count their occurrences within each zone, and create bounding boxes\n",
        "    zone_counts = classify_and_count_objects(original_image, zones)\n",
        "\n",
        "    # Extract true labels from the image file name (assuming file name contains true labels)\n",
        "    true_labels = [label.split('_')[0] for label in image_file.split('.')[0].split('_')[1:]]\n",
        "\n",
        "    # Extract predicted labels from the zone_counts dictionary\n",
        "    pred_labels = []\n",
        "    for zone_counts_dict in zone_counts.values():\n",
        "        pred_labels.extend(list(zone_counts_dict.keys()))\n",
        "\n",
        "    # Update true and predicted labels lists\n",
        "    true_labels_list.extend(true_labels)\n",
        "    pred_labels_list.extend(pred_labels)\n",
        "\n",
        "    # Create a figure and axis for plotting\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Plot the original image with the 4 zones\n",
        "    axs[0].imshow(original_image)\n",
        "    for zone_id, zone_coords in enumerate(zones):\n",
        "        rect = plt.Rectangle((zone_coords[0], zone_coords[1]),\n",
        "                             zone_coords[2] - zone_coords[0],\n",
        "                             zone_coords[3] - zone_coords[1],\n",
        "                             fill=False, edgecolor='red', linewidth=2)\n",
        "        axs[0].add_patch(rect)\n",
        "        axs[0].text(zone_coords[0] + 5, zone_coords[1] + 20, f'Zone {zone_id + 1}',\n",
        "                    color='red', fontsize=12, weight='bold')\n",
        "\n",
        "    # Plot the count information beside the image\n",
        "    axs[1].axis('off')\n",
        "    for zone_id, zone_counts_dict in zone_counts.items():\n",
        "        zone_str = f'Zone {zone_id + 1} Counts:\\n'\n",
        "        count_str = '\\n'.join([f'- {class_name}: {count}' for class_name, count in zone_counts_dict.items()])\n",
        "        axs[1].text(0.5, 0.95 - 0.25 * zone_id, zone_str + count_str,\n",
        "                    transform=axs[1].transAxes, fontsize=12, weight='bold')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the modified image with both the original image and counts\n",
        "    output_path = os.path.join(output_folder, f\"output1_{image_file}\")\n",
        "    plt.savefig(output_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Processed image with counts saved at: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zpE_E-0956Bx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}